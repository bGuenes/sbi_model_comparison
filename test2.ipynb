{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6cf1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ModelTransfuser import ModelTransfuser\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d4c1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name):\n",
    "    # --- Load in training data ---\n",
    "    path_training = os.getcwd() + f'/data/model_comp_data(AGB,SN2,SN1a)/{name}_train.npz'\n",
    "    training_data = np.load(path_training, mmap_mode='r')\n",
    "\n",
    "    train_theta = training_data['params']\n",
    "    train_x = training_data['abundances']\n",
    "\n",
    "    # ---  Load in the validation data ---\n",
    "    path_test = os.getcwd() + f'/data/model_comp_data(AGB,SN2,SN1a)/{name}_val.npz'\n",
    "    val_data = np.load(path_test, mmap_mode='r')\n",
    "\n",
    "    val_theta = val_data['params']\n",
    "    val_x = val_data['abundances']\n",
    "\n",
    "    # --- Clean the data ---\n",
    "    # Chempy sometimes returns zeros or infinite values, which need to removed\n",
    "    def clean_data(x, y):\n",
    "        # Remove all zeros from the training data\n",
    "        index = np.where((y == 0).all(axis=1))[0]\n",
    "        x = np.delete(x, index, axis=0)\n",
    "        y = np.delete(y, index, axis=0)\n",
    "\n",
    "        # Remove all infinite values from the training data\n",
    "        index = np.where(np.isfinite(y).all(axis=1))[0]\n",
    "        x = x[index]\n",
    "        y = y[index]\n",
    "\n",
    "        # Remove H from Elements\n",
    "        y = np.delete(y, 2, 1)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    train_theta, train_x = clean_data(train_theta, train_x)\n",
    "    val_theta, val_x     = clean_data(val_theta, val_x)\n",
    "\n",
    "    # convert to torch tensors\n",
    "    train_theta = torch.tensor(train_theta, dtype=torch.float32)\n",
    "    train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "    val_theta = torch.tensor(val_theta, dtype=torch.float32)\n",
    "    val_x = torch.tensor(val_x, dtype=torch.float32)\n",
    "\n",
    "    # --- add noise ---\n",
    "    pc_ab = 5 # percentage error in abundance\n",
    "\n",
    "    train_x_err = torch.ones_like(train_x)*float(pc_ab)/100.\n",
    "    train_x = norm.rvs(loc=train_x,scale=train_x_err)\n",
    "    train_x = torch.tensor(train_x).float()\n",
    "\n",
    "    val_x_err = torch.ones_like(val_x)*float(pc_ab)/100.\n",
    "    val_x = norm.rvs(loc=val_x,scale=val_x_err)\n",
    "    val_x = torch.tensor(val_x).float()\n",
    "\n",
    "    # --- Concatenate the data ---\n",
    "    # train_data = torch.cat((train_theta, train_x), 1)\n",
    "    # val_data = torch.cat((val_theta, val_x), 1)\n",
    "\n",
    "    return train_theta, train_x, val_theta, val_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd86d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [name.replace(\"_train.npz\",\"\") for name in os.listdir(\"data/model_comp_data(AGB,SN2,SN1a)/\") if \"train\" in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dff1d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MTf = ModelTransfuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "257929e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data added to model Karakas_net_yield_CL18_net_Seitenzahl\n",
      "Data added to model Karakas_net_yield_Frischknecht16_net_Seitenzahl\n",
      "Data added to model Karakas_net_yield_Nomoto2013_Seitenzahl\n",
      "Data added to model Karakas_net_yield_Nomoto2013_net_Seitenzahl\n",
      "Data added to model Karakas_net_yield_NuGrid_net_Seitenzahl\n",
      "Data added to model Karakas_net_yield_Portinari_net_Seitenzahl\n",
      "Data added to model Karakas_net_yield_TNG_net_Seitenzahl\n",
      "Data added to model Karakas_net_yield_West17_net_Seitenzahl\n",
      "Data added to model Karakas_net_yield_chieffi04_Seitenzahl\n",
      "Data added to model Karakas_net_yield_chieffi04_net_Seitenzahl\n",
      "Data added to model Nugrid_CL18_net_Seitenzahl\n",
      "Data added to model Nugrid_Frischknecht16_net_Seitenzahl\n",
      "Data added to model Nugrid_Nomoto2013_Seitenzahl\n",
      "Data added to model Nugrid_Nomoto2013_net_Seitenzahl\n",
      "Data added to model Nugrid_NuGrid_net_Seitenzahl\n",
      "Data added to model Nugrid_Portinari_net_Seitenzahl\n",
      "Data added to model Nugrid_TNG_net_Seitenzahl\n",
      "Data added to model Nugrid_West17_net_Seitenzahl\n",
      "Data added to model Nugrid_chieffi04_Seitenzahl\n",
      "Data added to model Nugrid_chieffi04_net_Seitenzahl\n",
      "Data added to model TNG_net_CL18_net_Seitenzahl\n",
      "Data added to model TNG_net_Frischknecht16_net_Seitenzahl\n",
      "Data added to model TNG_net_Nomoto2013_Seitenzahl\n",
      "Data added to model TNG_net_Nomoto2013_net_Seitenzahl\n",
      "Data added to model TNG_net_NuGrid_net_Seitenzahl\n",
      "Data added to model TNG_net_Portinari_net_Seitenzahl\n",
      "Data added to model TNG_net_TNG_net_Seitenzahl\n",
      "Data added to model TNG_net_West17_net_Seitenzahl\n",
      "Data added to model TNG_net_chieffi04_Seitenzahl\n",
      "Data added to model TNG_net_chieffi04_net_Seitenzahl\n",
      "Data added to model Ventura_net_CL18_net_Seitenzahl\n",
      "Data added to model Ventura_net_Frischknecht16_net_Seitenzahl\n",
      "Data added to model Ventura_net_Nomoto2013_Seitenzahl\n",
      "Data added to model Ventura_net_Nomoto2013_net_Seitenzahl\n",
      "Data added to model Ventura_net_NuGrid_net_Seitenzahl\n",
      "Data added to model Ventura_net_Portinari_net_Seitenzahl\n",
      "Data added to model Ventura_net_TNG_net_Seitenzahl\n",
      "Data added to model Ventura_net_West17_net_Seitenzahl\n",
      "Data added to model Ventura_net_chieffi04_Seitenzahl\n",
      "Data added to model Ventura_net_chieffi04_net_Seitenzahl\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    # --- Load in the data ---\n",
    "    train_theta, train_x, val_theta, val_x = load_data(name)\n",
    "\n",
    "    MTf.add_data(name, train_theta, train_x, val_theta, val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90eee28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized: ['Karakas_net_yield_CL18_net_Seitenzahl', 'Karakas_net_yield_Frischknecht16_net_Seitenzahl', 'Karakas_net_yield_Nomoto2013_Seitenzahl', 'Karakas_net_yield_Nomoto2013_net_Seitenzahl', 'Karakas_net_yield_NuGrid_net_Seitenzahl', 'Karakas_net_yield_Portinari_net_Seitenzahl', 'Karakas_net_yield_TNG_net_Seitenzahl', 'Karakas_net_yield_West17_net_Seitenzahl', 'Karakas_net_yield_chieffi04_Seitenzahl', 'Karakas_net_yield_chieffi04_net_Seitenzahl', 'Nugrid_CL18_net_Seitenzahl', 'Nugrid_Frischknecht16_net_Seitenzahl', 'Nugrid_Nomoto2013_Seitenzahl', 'Nugrid_Nomoto2013_net_Seitenzahl', 'Nugrid_NuGrid_net_Seitenzahl', 'Nugrid_Portinari_net_Seitenzahl', 'Nugrid_TNG_net_Seitenzahl', 'Nugrid_West17_net_Seitenzahl', 'Nugrid_chieffi04_Seitenzahl', 'Nugrid_chieffi04_net_Seitenzahl', 'TNG_net_CL18_net_Seitenzahl', 'TNG_net_Frischknecht16_net_Seitenzahl', 'TNG_net_Nomoto2013_Seitenzahl', 'TNG_net_Nomoto2013_net_Seitenzahl', 'TNG_net_NuGrid_net_Seitenzahl', 'TNG_net_Portinari_net_Seitenzahl', 'TNG_net_TNG_net_Seitenzahl', 'TNG_net_West17_net_Seitenzahl', 'TNG_net_chieffi04_Seitenzahl', 'TNG_net_chieffi04_net_Seitenzahl', 'Ventura_net_CL18_net_Seitenzahl', 'Ventura_net_Frischknecht16_net_Seitenzahl', 'Ventura_net_Nomoto2013_Seitenzahl', 'Ventura_net_Nomoto2013_net_Seitenzahl', 'Ventura_net_NuGrid_net_Seitenzahl', 'Ventura_net_Portinari_net_Seitenzahl', 'Ventura_net_TNG_net_Seitenzahl', 'Ventura_net_West17_net_Seitenzahl', 'Ventura_net_chieffi04_Seitenzahl', 'Ventura_net_chieffi04_net_Seitenzahl']\n"
     ]
    }
   ],
   "source": [
    "MTf.init_models(sde_type=\"vesde\", sigma=2.5, hidden_size=36, depth=5, num_heads=1, mlp_ratio=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb7d6600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W427 23:11:42.591615106 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mMTf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/big_MTf_model_comp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbi_model_comparison/src/ModelTransfuser.py:178\u001b[0m, in \u001b[0;36mModelTransfuser.train_models\u001b[0;34m(self, batch_size, max_epochs, lr, device, verbose, path, early_stopping_patience)\u001b[0m\n\u001b[1;32m    175\u001b[0m val_theta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dict[model_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_theta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m val_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dict[model_name]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_x\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 178\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_theta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m load_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels_dict[model_name] \u001b[38;5;241m=\u001b[39m SBIm\u001b[38;5;241m.\u001b[39mload(path\u001b[38;5;241m=\u001b[39mload_path, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/sbi_model_comparison/src/ScoreBasedInferenceModel.py:119\u001b[0m, in \u001b[0;36mScoreBasedInferenceModel.train\u001b[0;34m(self, theta, x, theta_val, x_val, batch_size, max_epochs, lr, device, verbose, path, name, early_stopping_patience)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m    117\u001b[0m     world_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbi_model_comparison/src/Trainer.py:87\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, world_size, train_data, val_data, max_epochs, early_stopping_patience, batch_size, lr, path, name, device, verbose)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-3\u001b[39m \u001b[38;5;66;03m# Epsilon for numerical stability and endpoint in diffusion process\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_loop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:340\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    334\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m     )\n\u001b[1;32m    339\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:296\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:144\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout, grace_period)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Wait for any process to fail or all of them to succeed.\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mmultiprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentinels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m error_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentinel \u001b[38;5;129;01min\u001b[39;00m ready:\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MTf.train_models(path=\"data/big_MTf_model_comp\", batch_size=512, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ae8126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simformer_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

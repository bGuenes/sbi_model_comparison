{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '2,3,4,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ModelTransfuser import ModelTransfuser as MTf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from scipy.stats import norm, gaussian_kde\n",
    "from scipy import optimize\n",
    "import scipy\n",
    "\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = \"842\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clean the data ---\n",
    "# Chempy sometimes returns zeros or infinite values, which need to removed\n",
    "def clean_data(x, y):\n",
    "    # Remove all zeros from the training data\n",
    "    index = np.where((y == 0).all(axis=1))[0]\n",
    "    x = np.delete(x, index, axis=0)\n",
    "    y = np.delete(y, index, axis=0)\n",
    "\n",
    "    # Remove all infinite values from the training data\n",
    "    index = np.where(np.isfinite(y).all(axis=1))[0]\n",
    "    x = x[index]\n",
    "    y = y[index]\n",
    "\n",
    "    # Remove H from Elements\n",
    "    y = np.delete(y, 2, 1)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  Load in the validation data ---\n",
    "path_test = os.getcwd() + f'/data/Chempy_model_comp_data/chempy_{data_model}_val.npz'\n",
    "val_data = np.load(path_test, mmap_mode='r')\n",
    "\n",
    "val_x = val_data['params']\n",
    "val_y = val_data['abundances']\n",
    "\n",
    "val_x, val_y = clean_data(val_x, val_y)\n",
    "\n",
    "# convert to torch tensors\n",
    "val_x = torch.tensor(val_x, dtype=torch.float32)\n",
    "val_y = torch.tensor(val_y, dtype=torch.float32)\n",
    "\n",
    "# --- add noise ---\n",
    "pc_ab = 5 # percentage error in abundance\n",
    "\n",
    "val_y_err = torch.ones_like(val_y)*float(pc_ab)/100.\n",
    "val_y = norm.rvs(loc=val_y,scale=val_y_err)\n",
    "val_y = torch.tensor(val_y).float()\n",
    "\n",
    "val_data = torch.cat((val_x, val_y), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ModelTransfuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ModelTransfuser\n",
    "model_442 = MTf.load('data/models/chempy_442/Model_checkpoint.pt')\n",
    "model_742 = MTf.load('data/models/chempy_742/Model_checkpoint.pt')\n",
    "model_842 = MTf.load('data/models/chempy_842/Model_checkpoint.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mask = torch.zeros_like(val_data[0])\n",
    "posterior_mask[6:] = 1\n",
    "\n",
    "data = val_data[:1000, posterior_mask.type(torch.bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n"
     ]
    }
   ],
   "source": [
    "null_hypothesis_442 = model_442.sample(torch.zeros(14), condition_mask=torch.zeros(14), device=\"cuda:0\", timesteps=100, cfg_alpha=None, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")\n",
    "null_hypothesis_742 = model_742.sample(torch.zeros(14), condition_mask=torch.zeros(14), device=\"cuda:0\", timesteps=100, cfg_alpha=None, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")\n",
    "null_hypothesis_842 = model_842.sample(torch.zeros(14), condition_mask=torch.zeros(14), device=\"cuda:0\", timesteps=100, cfg_alpha=None, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n"
     ]
    }
   ],
   "source": [
    "posterior_442 = model_442.sample(data[test_index], condition_mask=posterior_mask, device=\"cuda:0\", timesteps=100, cfg_alpha=None, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")\n",
    "posterior_742 = model_742.sample(data[test_index], condition_mask=posterior_mask, device=\"cuda:0\", timesteps=100, cfg_alpha=None, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")\n",
    "posterior_842 = model_842.sample(data[test_index], condition_mask=posterior_mask, device=\"cuda:0\", timesteps=100, cfg_alpha=None, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hat_442 = posterior_442.mean(dim=1)[:,:6]\n",
    "theta_hat_742 = posterior_742.mean(dim=1)[:,:6]\n",
    "theta_hat_842 = posterior_842.mean(dim=1)[:,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: tensor([-2.6000, -3.0300, -0.2485,  0.5487,  0.6439,  4.7983])\n",
      "Model 442: tensor([[-2.4996, -3.2523, -0.2283,  0.5770,  0.5139,  3.4783]])\n",
      "Model 742: tensor([[-1.7682, -3.4203, -0.0344,  0.6784,  0.5818,  3.6401]])\n",
      "Model 842: tensor([[-2.5492, -3.0041, -0.3442,  0.5649,  0.5084,  4.6112]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ground Truth: {val_data[test_index,:6]}\")\n",
    "print(f\"Model 442: {theta_hat_442}\")\n",
    "print(f\"Model 742: {theta_hat_742}\")\n",
    "print(f\"Model 842: {theta_hat_842}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_mask = torch.zeros_like(val_data[0])\n",
    "likelihood_mask[:6] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "likelihood_442 = model_442.sample(theta_hat_442, condition_mask=likelihood_mask, device=\"cuda:0\", timesteps=100, cfg_alpha=None, save_trajectory=True, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")\n",
    "likelihood_742 = model_742.sample(theta_hat_742, condition_mask=likelihood_mask, device=\"cuda:0\", timesteps=100, cfg_alpha=None, save_trajectory=True, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")\n",
    "likelihood_842 = model_842.sample(theta_hat_842, condition_mask=likelihood_mask, device=\"cuda:0\", timesteps=100, cfg_alpha=None, save_trajectory=True, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat_442 = likelihood_442.mean(dim=1)[:,6:]\n",
    "x_hat_742 = likelihood_742.mean(dim=1)[:,6:]\n",
    "x_hat_842 = likelihood_842.mean(dim=1)[:,6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: tensor([ 0.0706, -0.4739,  0.5001,  0.2298,  0.3004,  0.5244,  0.3445,  0.3691])\n",
      "Model 442: tensor([[ 0.2097, -0.3963,  0.3869,  0.1510,  0.1923,  0.5271,  0.3823,  0.2806]])\n",
      "Model 742: tensor([[-0.0060, -0.1841,  0.2954,  0.0054,  0.2617,  0.2265,  0.3573,  0.2811]])\n",
      "Model 842: tensor([[-0.0051, -0.4285,  0.4315,  0.1911,  0.2329,  0.4771,  0.3107,  0.2845]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ground Truth: {val_data[test_index,6:]}\")\n",
    "print(f\"Model 442: {x_hat_442}\")\n",
    "print(f\"Model 742: {x_hat_742}\")\n",
    "print(f\"Model 842: {x_hat_842}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_fn_442 = gaussian_kde(likelihood_442[0,:,6:].T.cpu().numpy())\n",
    "likelihood_fn_742 = gaussian_kde(likelihood_742[0,:,6:].T.cpu().numpy())\n",
    "likelihood_fn_842 = gaussian_kde(likelihood_842[0,:,6:].T.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_likelihood_fn_442 = gaussian_kde(null_hypothesis_442[0,:,6:].T.cpu().numpy())\n",
    "null_likelihood_fn_742 = gaussian_kde(null_hypothesis_742[0,:,6:].T.cpu().numpy())\n",
    "null_likelihood_fn_842 = gaussian_kde(null_hypothesis_842[0,:,6:].T.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood_value_442 = likelihood_fn_442.logpdf(data[test_index]).item()\n",
    "log_likelihood_value_742 = likelihood_fn_742.logpdf(data[test_index]).item()\n",
    "log_likelihood_value_842 = likelihood_fn_842.logpdf(data[test_index]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_null_likelihood_value_442 = null_likelihood_fn_442.logpdf(data[test_index]).item()\n",
    "log_null_likelihood_value_742 = null_likelihood_fn_742.logpdf(data[test_index]).item()\n",
    "log_null_likelihood_value_842 = null_likelihood_fn_842.logpdf(data[test_index]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood 442: 6.05\n",
      "Log Likelihood 742: 2.78\n",
      "Log Likelihood 842: 8.21\n"
     ]
    }
   ],
   "source": [
    "print(f\"Log Likelihood 442: {log_likelihood_value_442:.2f}\")\n",
    "print(f\"Log Likelihood 742: {log_likelihood_value_742:.2f}\")\n",
    "print(f\"Log Likelihood 842: {log_likelihood_value_842:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 fits the data best with a relative support of 89.3% among the considered models and could reject the null hypothesis strongly.\n"
     ]
    }
   ],
   "source": [
    "log_likelihoods = np.array([log_likelihood_value_442, log_likelihood_value_742, log_likelihood_value_842])\n",
    "model_prob = scipy.special.softmax(log_likelihoods)\n",
    "\n",
    "bayes_factor_null = [log_likelihood_value_442 - log_null_likelihood_value_442, log_likelihood_value_742 - log_null_likelihood_value_742, log_likelihood_value_842 - log_null_likelihood_value_842]\n",
    "hypothesis_test = \"could\" if bayes_factor_null[model_prob.argmax()] > 0 else \"could not\"\n",
    "\n",
    "hypothesis_test_strength = np.exp(bayes_factor_null[model_prob.argmax()])\n",
    "if 1 < hypothesis_test_strength <= 3.2:\n",
    "    hypothesis_test_strength = \"barley\"\n",
    "elif 3.2 < hypothesis_test_strength <= 10:\n",
    "    hypothesis_test_strength = \"substantially\"\n",
    "elif 10 < hypothesis_test_strength <= 100:\n",
    "    hypothesis_test_strength = \"strongly\"\n",
    "elif 100 < hypothesis_test_strength:\n",
    "    hypothesis_test_strength = \"decisively\"\n",
    "else:\n",
    "    hypothesis_test_strength = \"\"\n",
    "\n",
    "print(f\"Model {model_prob.argmax()+1} fits the data best with a relative support of {100*model_prob.max():.1f}% among the considered models and {hypothesis_test} reject the null hypothesis {hypothesis_test_strength}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simformer_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

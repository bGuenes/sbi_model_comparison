{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '2,3,4,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ScoreBasedInferenceModel import ScoreBasedInferenceModel as SBIm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from scipy.stats import norm, gaussian_kde\n",
    "from scipy import optimize\n",
    "import scipy\n",
    "\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = \"842\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clean the data ---\n",
    "# Chempy sometimes returns zeros or infinite values, which need to removed\n",
    "def clean_data(x, y):\n",
    "    # Remove all zeros from the training data\n",
    "    index = np.where((y == 0).all(axis=1))[0]\n",
    "    x = np.delete(x, index, axis=0)\n",
    "    y = np.delete(y, index, axis=0)\n",
    "\n",
    "    # Remove all infinite values from the training data\n",
    "    index = np.where(np.isfinite(y).all(axis=1))[0]\n",
    "    x = x[index]\n",
    "    y = y[index]\n",
    "\n",
    "    # Remove H from Elements\n",
    "    y = np.delete(y, 2, 1)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  Load in the validation data ---\n",
    "path_test = os.getcwd() + f'/data/Chempy_model_comp_data/chempy_{data_model}_val.npz'\n",
    "val_data = np.load(path_test, mmap_mode='r')\n",
    "\n",
    "val_x = val_data['params']\n",
    "val_y = val_data['abundances']\n",
    "\n",
    "val_x, val_y = clean_data(val_x, val_y)\n",
    "\n",
    "# convert to torch tensors\n",
    "val_x = torch.tensor(val_x, dtype=torch.float32)\n",
    "val_y = torch.tensor(val_y, dtype=torch.float32)\n",
    "\n",
    "# --- add noise ---\n",
    "pc_ab = 5 # percentage error in abundance\n",
    "\n",
    "val_y_err = torch.ones_like(val_y)*float(pc_ab)/100.\n",
    "val_y = norm.rvs(loc=val_y,scale=val_y_err)\n",
    "val_y = torch.tensor(val_y).float()\n",
    "\n",
    "val_data = torch.cat((val_x, val_y), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ModelTransfuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ModelTransfuser\n",
    "model_442 = SBIm.load('data/models/chempy_442/Model_checkpoint.pt')\n",
    "model_742 = SBIm.load('data/models/chempy_742/Model_checkpoint.pt')\n",
    "model_842 = SBIm.load('data/models/chempy_842/Model_checkpoint.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mask = torch.zeros_like(val_data[0])\n",
    "posterior_mask[6:] = 1\n",
    "\n",
    "data = val_data[:1000, posterior_mask.type(torch.bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n"
     ]
    }
   ],
   "source": [
    "null_hypothesis_442 = model_442.sample(torch.zeros(14), condition_mask=torch.zeros(14), device=\"cuda:0\", timesteps=100, cfg_alpha=None, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")\n",
    "null_hypothesis_742 = model_742.sample(torch.zeros(14), condition_mask=torch.zeros(14), device=\"cuda:0\", timesteps=100, cfg_alpha=None, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")\n",
    "null_hypothesis_842 = model_842.sample(torch.zeros(14), condition_mask=torch.zeros(14), device=\"cuda:0\", timesteps=100, cfg_alpha=None, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n"
     ]
    }
   ],
   "source": [
    "posterior_442 = model_442.sample(data[test_index], condition_mask=posterior_mask, device=\"cuda:0\", timesteps=100, cfg_alpha=None, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")\n",
    "posterior_742 = model_742.sample(data[test_index], condition_mask=posterior_mask, device=\"cuda:0\", timesteps=100, cfg_alpha=None, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")\n",
    "posterior_842 = model_842.sample(data[test_index], condition_mask=posterior_mask, device=\"cuda:0\", timesteps=100, cfg_alpha=None, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_mask.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.3169, -2.9535,  0.1727,  0.5660,  0.4562,  6.7417],\n",
       "         [-2.3815, -3.0777, -0.4272,  0.4362,  0.4904, 13.1684],\n",
       "         [-2.1150, -2.5096, -0.3913,  0.5760,  0.4802,  9.3550],\n",
       "         ...,\n",
       "         [-2.3705, -2.6471,  0.1634,  0.5051,  0.7053,  8.1304],\n",
       "         [-2.1569, -2.6800,  0.0134,  0.6350,  0.5855,  6.9629],\n",
       "         [-2.2496, -2.6100,  0.1382,  0.7796,  0.5011,  6.1941]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_442[:,:,(1-posterior_mask).bool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hat_442 = posterior_442.mean(dim=1)[:,:6]\n",
    "theta_hat_742 = posterior_742.mean(dim=1)[:,:6]\n",
    "theta_hat_842 = posterior_842.mean(dim=1)[:,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: tensor([-2.2482, -2.7791, -0.0193,  0.6013,  0.4290, 10.8796])\n",
      "Model 442: tensor([[-2.2340, -2.7413, -0.1437,  0.5273,  0.4616,  8.3242]])\n",
      "Model 742: tensor([[-1.6914, -3.0892, -0.0119,  0.6491,  0.5516,  8.4723]])\n",
      "Model 842: tensor([[-2.1733, -2.6000, -0.1935,  0.5262,  0.4630,  8.1301]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ground Truth: {val_data[test_index,:6]}\")\n",
    "print(f\"Model 442: {theta_hat_442}\")\n",
    "print(f\"Model 742: {theta_hat_742}\")\n",
    "print(f\"Model 842: {theta_hat_842}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_mask = torch.zeros_like(val_data[0])\n",
    "likelihood_mask[:6] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "likelihood_442 = model_442.sample(theta_hat_442, condition_mask=likelihood_mask, device=\"cuda:0\", timesteps=100, cfg_alpha=None, save_trajectory=True, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")\n",
    "likelihood_742 = model_742.sample(theta_hat_742, condition_mask=likelihood_mask, device=\"cuda:0\", timesteps=100, cfg_alpha=None, save_trajectory=True, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")\n",
    "likelihood_842 = model_842.sample(theta_hat_842, condition_mask=likelihood_mask, device=\"cuda:0\", timesteps=100, cfg_alpha=None, save_trajectory=True, corrector_steps=5, corrector_steps_interval=5, final_corrector_steps=10).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat_442 = likelihood_442.mean(dim=1)[:,6:]\n",
    "x_hat_742 = likelihood_742.mean(dim=1)[:,6:]\n",
    "x_hat_842 = likelihood_842.mean(dim=1)[:,6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: tensor([-0.0728,  0.2306, -0.3019,  0.1014,  0.0569,  0.4863,  0.2233,  0.1436])\n",
      "Model 442: tensor([[ 0.0066,  0.3272, -0.2645,  0.0880,  0.0804,  0.4275,  0.3083,  0.2780]])\n",
      "Model 742: tensor([[-0.1518,  0.2781, -0.0285, -0.0759,  0.2716,  0.1481,  0.2128,  0.2581]])\n",
      "Model 842: tensor([[-0.0335,  0.3066, -0.2292,  0.1254,  0.0293,  0.4364,  0.2202,  0.1805]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ground Truth: {val_data[test_index,6:]}\")\n",
    "print(f\"Model 442: {x_hat_442}\")\n",
    "print(f\"Model 742: {x_hat_742}\")\n",
    "print(f\"Model 842: {x_hat_842}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_fn_442 = gaussian_kde(likelihood_442[0,:,6:].T.cpu().numpy())\n",
    "likelihood_fn_742 = gaussian_kde(likelihood_742[0,:,6:].T.cpu().numpy())\n",
    "likelihood_fn_842 = gaussian_kde(likelihood_842[0,:,6:].T.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_likelihood_fn_442 = gaussian_kde(null_hypothesis_442[0,:,6:].T.cpu().numpy())\n",
    "null_likelihood_fn_742 = gaussian_kde(null_hypothesis_742[0,:,6:].T.cpu().numpy())\n",
    "null_likelihood_fn_842 = gaussian_kde(null_hypothesis_842[0,:,6:].T.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood_value_442 = likelihood_fn_442.logpdf(data[test_index]).item()\n",
    "log_likelihood_value_742 = likelihood_fn_742.logpdf(data[test_index]).item()\n",
    "log_likelihood_value_842 = likelihood_fn_842.logpdf(data[test_index]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_null_likelihood_value_442 = null_likelihood_fn_442.logpdf(data[test_index]).item()\n",
    "log_null_likelihood_value_742 = null_likelihood_fn_742.logpdf(data[test_index]).item()\n",
    "log_null_likelihood_value_842 = null_likelihood_fn_842.logpdf(data[test_index]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood 442: 6.40\n",
      "Log Likelihood 742: 0.44\n",
      "Log Likelihood 842: 7.36\n"
     ]
    }
   ],
   "source": [
    "print(f\"Log Likelihood 442: {log_likelihood_value_442:.2f}\")\n",
    "print(f\"Log Likelihood 742: {log_likelihood_value_742:.2f}\")\n",
    "print(f\"Log Likelihood 842: {log_likelihood_value_842:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 fits the data best with a relative support of 72.2% among the considered models and could reject the null hypothesis strongly.\n"
     ]
    }
   ],
   "source": [
    "log_likelihoods = np.array([log_likelihood_value_442, log_likelihood_value_742, log_likelihood_value_842])\n",
    "model_prob = scipy.special.softmax(log_likelihoods)\n",
    "\n",
    "bayes_factor_null = [log_likelihood_value_442 - log_null_likelihood_value_442, log_likelihood_value_742 - log_null_likelihood_value_742, log_likelihood_value_842 - log_null_likelihood_value_842]\n",
    "hypothesis_test = \"could\" if bayes_factor_null[model_prob.argmax()] > 0 else \"could not\"\n",
    "\n",
    "hypothesis_test_strength = np.exp(bayes_factor_null[model_prob.argmax()])\n",
    "if 1 < hypothesis_test_strength <= 3.2:\n",
    "    hypothesis_test_strength = \"barley\"\n",
    "elif 3.2 < hypothesis_test_strength <= 10:\n",
    "    hypothesis_test_strength = \"substantially\"\n",
    "elif 10 < hypothesis_test_strength <= 100:\n",
    "    hypothesis_test_strength = \"strongly\"\n",
    "elif 100 < hypothesis_test_strength:\n",
    "    hypothesis_test_strength = \"decisively\"\n",
    "else:\n",
    "    hypothesis_test_strength = \"\"\n",
    "\n",
    "print(f\"Model {model_prob.argmax()+1} fits the data best \" + \n",
    "      f\"with a relative support of {100*model_prob.max():.1f}% among the considered models \"+\n",
    "      f\"and {hypothesis_test} reject the null hypothesis {hypothesis_test_strength}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simformer_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

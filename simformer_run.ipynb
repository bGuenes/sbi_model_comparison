{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simformer.simformer import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load in training data ---\n",
    "path_training = os.getcwd() + '/simformer/data/chempy_TNG_train_data.npz'\n",
    "training_data = np.load(path_training, mmap_mode='r')\n",
    "\n",
    "elements = training_data['elements']\n",
    "train_x = training_data['params']\n",
    "train_y = training_data['abundances']\n",
    "\n",
    "\n",
    "# ---  Load in the validation data ---\n",
    "path_test = os.getcwd() + '/simformer/data/chempy_TNG_val_data.npz'\n",
    "val_data = np.load(path_test, mmap_mode='r')\n",
    "\n",
    "val_x = val_data['params']\n",
    "val_y = val_data['abundances']\n",
    "\n",
    "\n",
    "# --- Clean the data ---\n",
    "# Chempy sometimes returns zeros or infinite values, which need to removed\n",
    "def clean_data(x, y):\n",
    "    # Remove all zeros from the training data\n",
    "    index = np.where((y == 0).all(axis=1))[0]\n",
    "    x = np.delete(x, index, axis=0)\n",
    "    y = np.delete(y, index, axis=0)\n",
    "\n",
    "    # Remove all infinite values from the training data\n",
    "    index = np.where(np.isfinite(y).all(axis=1))[0]\n",
    "    x = x[index]\n",
    "    y = y[index]\n",
    "\n",
    "    # Remove H from Elements\n",
    "    y = np.delete(y, 2, 1)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train_x, train_y = clean_data(train_x, train_y)\n",
    "val_x, val_y     = clean_data(val_x, val_y)\n",
    "\n",
    "# convert to torch tensors\n",
    "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y, dtype=torch.float32)\n",
    "val_x = torch.tensor(val_x, dtype=torch.float32)\n",
    "val_y = torch.tensor(val_y, dtype=torch.float32)\n",
    "\n",
    "train_data = torch.cat((train_x, train_y), 1)\n",
    "val_data = torch.cat((val_x, val_y), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Simformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/bguenes/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Define the simformer\n",
    "\n",
    "# Time steps for the diffusion process\n",
    "T = 300\n",
    "t = torch.linspace(0, 1, T)\n",
    "\n",
    "simformer = Simformer(T, train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([498314, 14])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49824, 14])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msimformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_mask_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_mask_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbi_model_comparison/simformer/simformer.py:208\u001b[0m, in \u001b[0;36mSimformer.train\u001b[0;34m(self, data, condition_mask_data, batch_size, epochs, lr, device, val_data, condition_mask_val)\u001b[0m\n\u001b[1;32m    205\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(score, timestep, noise)\n\u001b[1;32m    206\u001b[0m     loss_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 208\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# Validation set if provided\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "simformer.train(train_data, condition_mask_data=torch.ones_like(train_data), val_data=val_data, condition_mask_val=torch.ones_like(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simformer.train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simformer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(simformer.state_dict(), \"simformer/models/simformer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = np.arange(0, len(simformer.train_loss))\n",
    "\n",
    "plt.plot(epoch, np.array(simformer.train_loss)/train_data.shape[0], label='Train Loss')\n",
    "plt.plot(epoch, np.array(simformer.val_loss)/val_data.shape[0], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simformer.load_state_dict(torch.load(\"simformer/models/simformer_first-model.pt\", weights_only=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random datapoints to denoise\n",
    "sample_data_t1 = torch.randn(1000, train_data.shape[1])*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:25<00:00,  3.51it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_data_t0 = simformer.sample(sample_data_t1, condition_mask=torch.ones_like(sample_data_t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2223, -2.9067, -0.3161,  0.5714,  0.5094,  3.9033,  0.1574, -0.3034,\n",
       "         0.3284,  0.3827,  0.1627,  0.6785,  0.4863,  0.3420])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_t0.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0079, 0.0065, 0.0044, 0.0055, 0.0056, 0.2528, 0.0103, 0.0282, 0.0238,\n",
       "        0.0108, 0.0086, 0.0096, 0.0110, 0.0119])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_t0.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = [-2.3, -2.89, -0.3, 0.55, 0.5]\n",
    "sigma = [0.3, 0.3, 0.3, 0.1, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoising_data = simformer.x_t.detach().numpy()\n",
    "score_t = simformer.score_t.detach().numpy()\n",
    "t = simformer.t.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 301, 14)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoising_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/matplotlib/animation.py:223\u001b[0m, in \u001b[0;36mAbstractMovieWriter.saving\u001b[0;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/matplotlib/animation.py:1072\u001b[0m, in \u001b[0;36mAnimation.save\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m anim \u001b[38;5;129;01min\u001b[39;00m all_anim:\n\u001b[0;32m-> 1072\u001b[0m     \u001b[43manim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_draw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Clear the initial frame\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m frame_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/matplotlib/animation.py:1727\u001b[0m, in \u001b[0;36mFuncAnimation._init_draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1727\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/matplotlib/animation.py:1746\u001b[0m, in \u001b[0;36mFuncAnimation._draw_frame\u001b[0;34m(self, framedata)\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;66;03m# Call the func with framedata and args. If blitting is desired,\u001b[39;00m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# func needs to return a sequence of any artists that were modified.\u001b[39;00m\n\u001b[0;32m-> 1746\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drawn_artists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframedata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blit:\n",
      "Cell \u001b[0;32mIn[67], line 17\u001b[0m, in \u001b[0;36manimate\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#plt.axvline(priors[0], color='r', ls=\"--\", alpha=0.5)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#plt.axhline(priors[1], color='r', ls=\"--\", alpha=0.5)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatches\u001b[49m\u001b[38;5;241m.\u001b[39mEllipse((priors[\u001b[38;5;241m0\u001b[39m], priors[\u001b[38;5;241m1\u001b[39m]), width\u001b[38;5;241m=\u001b[39msigma[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, height\u001b[38;5;241m=\u001b[39msigma[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mquiver(denoising_data[:,i,\u001b[38;5;241m0\u001b[39m], denoising_data[:,i,\u001b[38;5;241m1\u001b[39m], score_t[:,i,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mscaling_factor[i], score_t[:,i,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mscaling_factor[i])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'patches'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 31\u001b[0m\n\u001b[1;32m     26\u001b[0m ani2 \u001b[38;5;241m=\u001b[39m matplotlib\u001b[38;5;241m.\u001b[39manimation\u001b[38;5;241m.\u001b[39mFuncAnimation(fig, animate, frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m) \n\u001b[1;32m     28\u001b[0m writer \u001b[38;5;241m=\u001b[39m matplotlib\u001b[38;5;241m.\u001b[39manimation\u001b[38;5;241m.\u001b[39mPillowWriter(fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     29\u001b[0m                                 metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(artist\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMe\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     30\u001b[0m                                 bitrate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1800\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[43mani2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplots/test_big.gif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03mplt.scatter(denoising_data[:,0,0], denoising_data[:,0,1], s=0.5)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03mfor i in range(len(denoising_data)):\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    plt.arrow(denoising_data[i,0,0], denoising_data[i,0,1], score_t[i,0,0]*scaling_factor[0], score_t[i,0,1]*scaling_factor[0], color='b', head_width=0.03)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03mplt.show()\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/matplotlib/animation.py:1069\u001b[0m, in \u001b[0;36mAnimation.save\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[1;32m   1065\u001b[0m savefig_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransparent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m   \u001b[38;5;66;03m# just to be safe!\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;66;03m# canvas._is_saving = True makes the draw_event animation-starting\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;66;03m# callback a no-op; canvas.manager = None prevents resizing the GUI\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# widget (both are likewise done in savefig()).\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m writer\u001b[38;5;241m.\u001b[39msaving(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fig, filename, dpi), \\\n\u001b[1;32m   1070\u001b[0m      cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fig\u001b[38;5;241m.\u001b[39mcanvas, _is_saving\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1071\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m anim \u001b[38;5;129;01min\u001b[39;00m all_anim:\n\u001b[1;32m   1072\u001b[0m         anim\u001b[38;5;241m.\u001b[39m_init_draw()  \u001b[38;5;66;03m# Clear the initial frame\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    151\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/matplotlib/animation.py:225\u001b[0m, in \u001b[0;36mAbstractMovieWriter.saving\u001b[0;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/matplotlib/animation.py:495\u001b[0m, in \u001b[0;36mPillowWriter.finish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinish\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 495\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_frames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msave(\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutfile, save_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, append_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frames[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    497\u001b[0m         duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfps), loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "scaling_factor = -0.5*simformer.sigma**(2*t)*(1/T)\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams['figure.dpi'] = 150  \n",
    "plt.ioff()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def animate(i):\n",
    "    plt.clf()\n",
    "    plt.xlim(-5,5)\n",
    "    plt.ylim(-5,5)\n",
    "    plt.xlabel(r'$\\alpha_{IMF}$')\n",
    "    plt.ylabel(r'$\\log_{10}N$')\n",
    "    #plt.axvline(priors[0], color='r', ls=\"--\", alpha=0.5)\n",
    "    #plt.axhline(priors[1], color='r', ls=\"--\", alpha=0.5)\n",
    "\n",
    "    plt.patches.Ellipse((priors[0], priors[1]), width=sigma[0]*2, height=sigma[1]*2)\n",
    "\n",
    "    plt.quiver(denoising_data[:,i,0], denoising_data[:,i,1], score_t[:,i,0]*scaling_factor[i], score_t[:,i,1]*scaling_factor[i])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #plt.scatter(denoising_data[:,i,0], denoising_data[:,i,1], s=0.5)\n",
    "    #for j in range(len(denoising_data)):\n",
    "    #    plt.arrow(denoising_data[j,i,0], denoising_data[j,i,1], score_t[j,i,0]*scaling_factor[i], score_t[j,i,1]*scaling_factor[i], color='black', head_width=0.05, alpha=0.6)\n",
    "\n",
    "ani2 = matplotlib.animation.FuncAnimation(fig, animate, frames=20) \n",
    "\n",
    "writer = matplotlib.animation.PillowWriter(fps=5,\n",
    "                                metadata=dict(artist='Me'),\n",
    "                                bitrate=1800)\n",
    "ani2.save('plots/test_big.gif', writer=writer)\n",
    "\n",
    "\"\"\"\n",
    "plt.scatter(denoising_data[:,0,0], denoising_data[:,0,1], s=0.5)\n",
    "for i in range(len(denoising_data)):\n",
    "    plt.arrow(denoising_data[i,0,0], denoising_data[i,0,1], score_t[i,0,0]*scaling_factor[0], score_t[i,0,1]*scaling_factor[0], color='b', head_width=0.03)\n",
    "\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams['figure.dpi'] = 150  \n",
    "plt.ioff()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "t = torch.linspace(0, 1, T)\n",
    "\n",
    "def animate2(i):\n",
    "    data_t = denoising_data[:,i,:6]\n",
    "    plt.cla()\n",
    "    for n in range(data_t.shape[1]):\n",
    "        plt.hist(data_t[:,n], bins=500, range=(-2,2), density=True, alpha=0.5)\n",
    "    plt.xlim([-2,2])\n",
    "    plt.ylim([0,2.5])\n",
    "    plt.title(f\"t={int(i)}\")\n",
    "\n",
    "ani2 = matplotlib.animation.FuncAnimation(fig, animate2, frames=299) \n",
    "\n",
    "writer = matplotlib.animation.PillowWriter(fps=20,\n",
    "                                metadata=dict(artist='Me'),\n",
    "                                bitrate=1800)\n",
    "ani2.save('plots/noise_to_x.gif', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ['red', 'blue', 'green', 'purple', 'orange', 'black']\n",
    "\n",
    "for i in range(5):\n",
    "    plt.hist(sample_data_t0[:, i], bins=500, range=(-5,5), density=True, alpha=0.5, color=color[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animate Diffusion Process\n",
    "Diffusion process to create the data for score training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams['figure.dpi'] = 150  \n",
    "plt.ioff()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "t = torch.linspace(0, 1, T)\n",
    "color = ['red', 'blue', 'green', 'purple', 'orange', 'black']\n",
    "\n",
    "def animate(i):\n",
    "    data_t = simformer.forward_diffusion_sample(data[:,:6], t[i])\n",
    "    plt.cla()\n",
    "    for n in range(data_t.shape[1]):\n",
    "        plt.hist(data_t[:,n], bins=500, range=(-5,15), density=True, alpha=0.5, color=color[n])\n",
    "    plt.xlim([-5,15])\n",
    "    plt.ylim([0,1])\n",
    "    plt.title(f\"t={int(i)}\")\n",
    "\n",
    "\"\"\"\n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=299)\n",
    "\n",
    "writer = matplotlib.animation.PillowWriter(fps=20,\n",
    "                                metadata=dict(artist='Me'),\n",
    "                                bitrate=1800)\n",
    "ani.save('../plots/theta_to_noise.gif', writer=writer)\n",
    "\"\"\"\n",
    "matplotlib.animation.FuncAnimation(fig, animate, frames=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams['figure.dpi'] = 150  \n",
    "plt.ioff()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "t = torch.linspace(0, 1, T)\n",
    "\n",
    "def animate2(i):\n",
    "    data_t = simformer.forward_diffusion_sample(data[:,7:], t[i])\n",
    "    plt.cla()\n",
    "    for n in range(data_t.shape[1]):\n",
    "        plt.hist(data_t[:,n], bins=500, range=(-2,2), density=True, alpha=0.5)\n",
    "    plt.xlim([-2,2])\n",
    "    plt.ylim([0,2.5])\n",
    "    plt.title(f\"t={int(i)}\")\n",
    "\n",
    "ani2 = matplotlib.animation.FuncAnimation(fig, animate2, frames=299) \n",
    "\n",
    "writer = matplotlib.animation.PillowWriter(fps=20,\n",
    "                                metadata=dict(artist='Me'),\n",
    "                                bitrate=1800)\n",
    "ani2.save('../plots/x_to_noise.gif', writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones(data[:10].shape[0],1)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = simformer.forward_transformer(data[:10], torch.ones(data[:10].shape[0],1)*10, condition_mask=torch.ones_like(data[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simformer_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

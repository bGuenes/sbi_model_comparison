{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelTransfuser.ModelTransfuser import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load in training data ---\n",
    "path_training = os.getcwd() + '/ModelTransfuser/data/chempy_TNG_train_data.npz'\n",
    "training_data = np.load(path_training, mmap_mode='r')\n",
    "\n",
    "elements = training_data['elements']\n",
    "train_x = training_data['params']\n",
    "train_y = training_data['abundances']\n",
    "\n",
    "\n",
    "# ---  Load in the validation data ---\n",
    "path_test = os.getcwd() + '/ModelTransfuser/data/chempy_TNG_val_data.npz'\n",
    "val_data = np.load(path_test, mmap_mode='r')\n",
    "\n",
    "val_x = val_data['params']\n",
    "val_y = val_data['abundances']\n",
    "\n",
    "\n",
    "# --- Clean the data ---\n",
    "# Chempy sometimes returns zeros or infinite values, which need to removed\n",
    "def clean_data(x, y):\n",
    "    # Remove all zeros from the training data\n",
    "    index = np.where((y == 0).all(axis=1))[0]\n",
    "    x = np.delete(x, index, axis=0)\n",
    "    y = np.delete(y, index, axis=0)\n",
    "\n",
    "    # Remove all infinite values from the training data\n",
    "    index = np.where(np.isfinite(y).all(axis=1))[0]\n",
    "    x = x[index]\n",
    "    y = y[index]\n",
    "\n",
    "    # Remove H from Elements\n",
    "    y = np.delete(y, 2, 1)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train_x, train_y = clean_data(train_x, train_y)\n",
    "val_x, val_y     = clean_data(val_x, val_y)\n",
    "\n",
    "# convert to torch tensors\n",
    "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y, dtype=torch.float32)\n",
    "val_x = torch.tensor(val_x, dtype=torch.float32)\n",
    "val_y = torch.tensor(val_y, dtype=torch.float32)\n",
    "\n",
    "train_data = torch.cat((train_x, train_y), 1)\n",
    "val_data = torch.cat((val_x, val_y), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ModelTransfuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/bguenes/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Define the ModelTransfuser\n",
    "\n",
    "# Time steps for the diffusion process\n",
    "T = 50\n",
    "t = torch.linspace(0, 1, T)\n",
    "\n",
    "model = ModelTransfuser(T, train_data.shape)\n",
    "\n",
    "#model = model.load('ModelTransfuser/models/ModelTransfuser_t50_normed.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization parameters set.\n"
     ]
    }
   ],
   "source": [
    "model.set_normalization(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/10: 100%|██████████| 157/157 [00:06<00:00, 24.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss: 5746451.000 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  2/10: 100%|██████████| 157/157 [00:04<00:00, 32.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss: 1206226.750 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  3/10: 100%|██████████| 157/157 [00:04<00:00, 32.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss: 1048005.188 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  4/10: 100%|██████████| 157/157 [00:04<00:00, 34.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  954147.438 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  5/10: 100%|██████████| 157/157 [00:04<00:00, 33.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  873816.062 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  6/10: 100%|██████████| 157/157 [00:04<00:00, 32.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  842340.562 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  7/10: 100%|██████████| 157/157 [00:04<00:00, 32.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  807878.750 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  8/10: 100%|██████████| 157/157 [00:04<00:00, 32.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  772841.750 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  9/10: 100%|██████████| 157/157 [00:05<00:00, 31.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  795940.438 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 157/157 [00:05<00:00, 30.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  761645.125 ---\n",
      "\n",
      "Training finished after 0.9 minutes\n",
      "Time 1: 0.03 s\n",
      "Time 2: 0.14 s\n",
      "Time 2a: 0.00 s\n",
      "Time 3: 0.17 s\n",
      "Time 4: 15.56 s\n",
      "Time 5: 0.31 s\n",
      "Time 6: 33.04 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(train_data[:10000], epochs=10, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/10:   0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/10: 100%|██████████| 157/157 [00:03<00:00, 46.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  751083.750 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  2/10: 100%|██████████| 157/157 [00:03<00:00, 41.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  729657.625 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  3/10: 100%|██████████| 157/157 [00:03<00:00, 43.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  721386.000 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  4/10: 100%|██████████| 157/157 [00:03<00:00, 49.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  720746.062 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  5/10: 100%|██████████| 157/157 [00:02<00:00, 62.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  722917.062 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  6/10: 100%|██████████| 157/157 [00:03<00:00, 45.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  710446.062 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  7/10: 100%|██████████| 157/157 [00:03<00:00, 48.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  683509.812 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  8/10: 100%|██████████| 157/157 [00:03<00:00, 52.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  715949.188 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  9/10: 100%|██████████| 157/157 [00:03<00:00, 50.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  723799.125 ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 157/157 [00:03<00:00, 48.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Loss:  718666.562 ---\n",
      "\n",
      "Training finished after 0.5 minutes\n",
      "Time 1: 0.05 s\n",
      "Time 2: 0.37 s\n",
      "Time 2a: 0.00 s\n",
      "Time 3: 0.37 s\n",
      "Time 4: 10.86 s\n",
      "Time 5: 0.61 s\n",
      "Time 6: 19.22 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(train_data[:10000], epochs=10, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ModelTransfuser/models/ModelTransfuser_t50_e50_normed.pickle', 'rb') as f:\n",
    "    ModelTransfuser = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ModelTransfuser' has no attribute 'train_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m epoch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mModelTransfuser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loss\u001b[49m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epoch, np\u001b[38;5;241m.\u001b[39marray(ModelTransfuser\u001b[38;5;241m.\u001b[39mtrain_loss)\u001b[38;5;241m/\u001b[39mtrain_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epoch, np\u001b[38;5;241m.\u001b[39marray(ModelTransfuser\u001b[38;5;241m.\u001b[39mval_loss)\u001b[38;5;241m/\u001b[39mval_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'ModelTransfuser' has no attribute 'train_loss'"
     ]
    }
   ],
   "source": [
    "epoch = np.arange(0, len(ModelTransfuser.train_loss))\n",
    "\n",
    "plt.plot(epoch, np.array(ModelTransfuser.train_loss)/train_data.shape[0], label='Train Loss')\n",
    "plt.plot(epoch, np.array(ModelTransfuser.val_loss)/val_data.shape[0], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random datapoints to denoise\n",
    "sample_data_t1 = torch.randn(10000, train_data.shape[1])*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]Exception ignored in: <generator object tqdm.__iter__ at 0x7ed61a5ecc80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/export/home/bguenes/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/tqdm/std.py\", line 1182, in __iter__\n",
      "    yield obj\n",
      "KeyboardInterrupt: \n",
      "  0%|          | 0/50 [00:56<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sample_data_t0 \u001b[38;5;241m=\u001b[39m \u001b[43mModelTransfuser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_data_t1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_data_t1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbi_model_comparison/ModelTransfuser/ModelTransfuser.py:289\u001b[0m, in \u001b[0;36mModelTransfuser.sample\u001b[0;34m(self, data, condition_mask, num_samples)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt)), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimesteps):\n\u001b[1;32m    288\u001b[0m     timestep \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 289\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_mask_samples\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    290\u001b[0m     dx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mtimestep)\u001b[38;5;241m*\u001b[39m score \u001b[38;5;241m*\u001b[39m dt\n\u001b[1;32m    291\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m-\u001b[39m dx \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mcondition_mask)\n",
      "File \u001b[0;32m~/sbi_model_comparison/ModelTransfuser/ModelTransfuser.py:168\u001b[0m, in \u001b[0;36mModelTransfuser.forward_transformer\u001b[0;34m(self, x, timestep, condition_mask, edge_mask)\u001b[0m\n\u001b[1;32m    164\u001b[0m x_encoded \u001b[38;5;241m=\u001b[39m x_encoded\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Transformer expects (seq_len, batch_size, d_model)\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# --- Transformer ---\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Transformer forward pass\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m transformer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_encoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m transformer_output \u001b[38;5;241m=\u001b[39m transformer_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Reorder back to (batch_size, seq_len, d_model)\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# --- Output decoding ---\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Score estimate output layer\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/transformer.py:217\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model \u001b[38;5;129;01mor\u001b[39;00m tgt\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 217\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(tgt, memory, tgt_mask\u001b[38;5;241m=\u001b[39mtgt_mask, memory_mask\u001b[38;5;241m=\u001b[39mmemory_mask,\n\u001b[1;32m    220\u001b[0m                       tgt_key_padding_mask\u001b[38;5;241m=\u001b[39mtgt_key_padding_mask,\n\u001b[1;32m    221\u001b[0m                       memory_key_padding_mask\u001b[38;5;241m=\u001b[39mmemory_key_padding_mask,\n\u001b[1;32m    222\u001b[0m                       tgt_is_causal\u001b[38;5;241m=\u001b[39mtgt_is_causal, memory_is_causal\u001b[38;5;241m=\u001b[39mmemory_is_causal)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/transformer.py:415\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    412\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 415\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    418\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/transformer.py:749\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    747\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 749\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    750\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/transformer.py:757\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    756\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 757\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/activation.py:1266\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1253\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1264\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1266\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/functional.py:5364\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[1;32m   5363\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 5364\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5365\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5366\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/functional.py:4886\u001b[0m, in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   4884\u001b[0m     proj \u001b[38;5;241m=\u001b[39m linear(q, w, b)\n\u001b[1;32m   4885\u001b[0m     \u001b[38;5;66;03m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n\u001b[0;32m-> 4886\u001b[0m     proj \u001b[38;5;241m=\u001b[39m \u001b[43mproj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m proj[\u001b[38;5;241m0\u001b[39m], proj[\u001b[38;5;241m1\u001b[39m], proj[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   4888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4889\u001b[0m     \u001b[38;5;66;03m# encoder-decoder attention\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sample_data_t0 = ModelTransfuser.sample(sample_data_t1, condition_mask=torch.zeros_like(sample_data_t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_data_t0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msample_data_t0\u001b[49m\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_data_t0' is not defined"
     ]
    }
   ],
   "source": [
    "sample_data_t0.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0143, 0.0141, 0.0105, 0.0072, 0.0073, 0.4777, 0.0127, 0.0460, 0.0484,\n",
       "        0.0156, 0.0125, 0.0146, 0.0169, 0.0156])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_t0.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = [-2.3, -2.89, -0.3, 0.55, 0.5]\n",
    "sigma = [0.3, 0.3, 0.3, 0.1, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoising_data = ModelTransfuser.x_t.detach().numpy()\n",
    "score_t = ModelTransfuser.score_t.detach().numpy()\n",
    "dx = ModelTransfuser.dx_t.detach().numpy()\n",
    "t = ModelTransfuser.t.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factor = -0.5*ModelTransfuser.sigma**(2*t)*(1/T)\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams['figure.dpi'] = 500  \n",
    "plt.ioff()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def animate(i):\n",
    "    plt.clf()\n",
    "    plt.xlim(-5,5)\n",
    "    plt.ylim(-5,5)\n",
    "    plt.xlabel(r'$\\alpha_{IMF}$')\n",
    "    plt.ylabel(r'$\\log_{10}N$')\n",
    "    plt.title(f'Denoising Timestep: {i}')\n",
    "\n",
    "    sns.set_style(\"white\")\n",
    "    sns.kdeplot(x=denoising_data[:,i,0], y=denoising_data[:,i,1], cmap='Blues', fill=True, levels=100, bw_adjust=0.6)\n",
    "    plt.tight_layout()\n",
    "\n",
    "ani2 = matplotlib.animation.FuncAnimation(fig, animate, frames=25) \n",
    "\n",
    "writer = matplotlib.animation.PillowWriter(fps=5,\n",
    "                                bitrate=-1)\n",
    "ani2.save('plots/test.gif', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoising_data[0,1,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams['figure.dpi'] = 500  \n",
    "plt.ioff()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def animate(i):\n",
    "    plt.clf()\n",
    "    plt.xlim(-5,5)\n",
    "    plt.ylim(-5,5)\n",
    "    plt.xlabel(r'$\\alpha_{IMF}$')\n",
    "    plt.ylabel(r'$\\log_{10}N$')\n",
    "    plt.title(f'Denoising Timestep: {i}')\n",
    "\n",
    "    plt.quiver(denoising_data[0,:i+1,0], denoising_data[0,:i+1,1], -dx[0,:i+1,0], -dx[0,:i+1,1], scale=1, scale_units='xy', width=0.003)\n",
    "    plt.scatter(denoising_data[0,:i+1,0], denoising_data[0,:i+1,1], s=20, marker='x', color='black')\n",
    "    #plt.hist2d(denoising_data[:,i,0], denoising_data[:,i,1])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #plt.scatter(denoising_data[:,i,0], denoising_data[:,i,1], s=0.5)\n",
    "    #for j in range(len(denoising_data)):\n",
    "    #    plt.arrow(denoising_data[j,i,0], denoising_data[j,i,1], score_t[j,i,0]*scaling_factor[i], score_t[j,i,1]*scaling_factor[i], color='black', head_width=0.05, alpha=0.6)\n",
    "\n",
    "ani2 = matplotlib.animation.FuncAnimation(fig, animate, frames=25) \n",
    "\n",
    "writer = matplotlib.animation.PillowWriter(fps=5,\n",
    "                                bitrate=-1)\n",
    "ani2.save('plots/test_quiver.gif', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7104, -2.8187,  0.0938,  0.5076,  0.4899,  4.5705, -0.0844, -0.2125,\n",
       "          0.2124, -0.0435, -0.0080,  0.2303,  0.0644,  0.0697]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.zeros_like(val_data[0])\n",
    "mask[6:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelTransfuser' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mModelTransfuser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbi_model_comparison/ModelTransfuser/ModelTransfuser.py:289\u001b[0m, in \u001b[0;36mModelTransfuser.sample\u001b[0;34m(self, data, condition_mask, num_samples)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, condition_mask, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1_000\u001b[39m):\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# Normalize data\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     data_normed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;66;03m#x = data_normed.repeat(num_samples, 1)\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     x \u001b[38;5;241m=\u001b[39m data_normed\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m,num_samples,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/sbi_model_comparison/ModelTransfuser/ModelTransfuser.py:134\u001b[0m, in \u001b[0;36mModelTransfuser.normalize\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    Normalize input data using the stored mean and std.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormalization parameters are not set. Use `set_normalization` first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (x \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ModelTransfuser' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "ModelTransfuser.sample(data=val_data[0], condition_mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:10<00:00,  4.98it/s]\n"
     ]
    }
   ],
   "source": [
    "p = ModelTransfuser.sample(val_data[1:2], condition_mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.0732, -2.8269, -0.3006,  0.5711,  0.5224,  9.5894,  0.1854,  0.1740,\n",
      "        -0.1011,  0.3229,  0.0553,  0.6386,  0.4327,  0.2450])\n",
      "tensor([0.0121, 0.0178, 0.0107, 0.0049, 0.0048, 0.1372, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "tensor([[-2.0697, -2.7872, -0.3723,  0.4962,  0.4666,  7.0081,  0.1854,  0.1740,\n",
      "         -0.1011,  0.3229,  0.0553,  0.6386,  0.4327,  0.2450]])\n"
     ]
    }
   ],
   "source": [
    "print(p.mean(axis=0))\n",
    "print(p.std(axis=0))\n",
    "print(val_data[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.4840e-03,  3.9677e-02, -7.1664e-02, -7.4929e-02, -5.5735e-02,\n",
       "         -2.5813e+00, -2.9802e-08,  0.0000e+00, -3.7253e-08, -5.9605e-08,\n",
       "         -3.7253e-09, -1.1921e-07, -1.7881e-07, -5.9605e-08]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val_data[1:2]-p.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p[2,:,1], bins=100)\n",
    "plt.hist(p[2,:,0], bins=100)\n",
    "plt.vlines(val_data[2,1], 0, 100, color='red')\n",
    "plt.vlines(val_data[2,0], 0, 100, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.zeros_like(val_data[0])\n",
    "mask[6:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:13<00:00,  3.94it/s]\n"
     ]
    }
   ],
   "source": [
    "p = model.sample(val_data[:1000], condition_mask=mask.repeat(1000,1), device=\"cuda:1\").to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "multinomial only supports floating-point dtypes for input, got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: multinomial only supports floating-point dtypes for input, got: Long"
     ]
    }
   ],
   "source": [
    "torch.tensor([1,2,3]).multinomial(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  3.8102,   4.0290, 294.3724,  15.3292,  18.1108,  32.4858])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(100*torch.abs((val_data[:1000]-p.mean(axis=1))/val_data[:1000]), axis=0)[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 14])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.mean(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6637, -2.8023, -0.2915,  0.5806,  0.5314,  7.5150],\n",
       "        [-2.1139, -2.8658, -0.2710,  0.5616,  0.5103,  9.6454],\n",
       "        [-2.1077, -3.0442, -0.3620,  0.5666,  0.5188,  6.0581],\n",
       "        ...,\n",
       "        [-2.3177, -2.8256, -0.3497,  0.5750,  0.5283,  5.6773],\n",
       "        [-2.0414, -2.7940, -0.2511,  0.5571,  0.5052, 10.2568],\n",
       "        [-2.4953, -3.0417, -0.3981,  0.5700,  0.5309,  3.4036]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.mean(axis=1)[:,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7104, -2.8187,  0.0938,  0.5076,  0.4899,  4.5705],\n",
       "        [-2.0697, -2.7872, -0.3723,  0.4962,  0.4666,  7.0081],\n",
       "        [-1.9933, -2.9700, -0.6510,  0.7150,  0.5921,  8.1804],\n",
       "        ...,\n",
       "        [-2.2048, -2.6840, -0.1035,  0.3844,  0.5521,  2.4740],\n",
       "        [-1.9363, -2.7056, -0.1936,  0.5923,  0.6127,  9.3704],\n",
       "        [-2.5485, -3.0766, -0.6182,  0.5331,  0.6020,  4.3152]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[:1000,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simformer_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,4,5,7,8,9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ModelTransfuser import ModelTransfuser\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.stats import norm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_model):\n",
    "    # -------------------------------------\n",
    "    # Load data\n",
    "\n",
    "    # --- Load in training data ---\n",
    "    path_training = os.getcwd() + f'/data/Chempy_model_comp_data/chempy_{data_model}.npz'\n",
    "    training_data = np.load(path_training, mmap_mode='r')\n",
    "\n",
    "    elements = training_data['elements']\n",
    "    train_x = training_data['params']\n",
    "    train_y = training_data['abundances']\n",
    "\n",
    "    # ---  Load in the validation data ---\n",
    "    path_test = os.getcwd() + f'/data/Chempy_model_comp_data/chempy_{data_model}_val.npz'\n",
    "    val_data = np.load(path_test, mmap_mode='r')\n",
    "\n",
    "    val_x = val_data['params']\n",
    "    val_y = val_data['abundances']\n",
    "\n",
    "    # --- Clean the data ---\n",
    "    # Chempy sometimes returns zeros or infinite values, which need to removed\n",
    "    def clean_data(x, y):\n",
    "        # Remove all zeros from the training data\n",
    "        index = np.where((y == 0).all(axis=1))[0]\n",
    "        x = np.delete(x, index, axis=0)\n",
    "        y = np.delete(y, index, axis=0)\n",
    "\n",
    "        # Remove all infinite values from the training data\n",
    "        index = np.where(np.isfinite(y).all(axis=1))[0]\n",
    "        x = x[index]\n",
    "        y = y[index]\n",
    "\n",
    "        # Remove H from Elements\n",
    "        y = np.delete(y, 2, 1)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    train_x, train_y = clean_data(train_x, train_y)\n",
    "    val_x, val_y     = clean_data(val_x, val_y)\n",
    "\n",
    "    # convert to torch tensors\n",
    "    train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "    train_y = torch.tensor(train_y, dtype=torch.float32)\n",
    "    val_x = torch.tensor(val_x, dtype=torch.float32)\n",
    "    val_y = torch.tensor(val_y, dtype=torch.float32)\n",
    "\n",
    "    # --- add noise ---\n",
    "    pc_ab = 5 # percentage error in abundance\n",
    "\n",
    "    train_y_err = torch.ones_like(train_y)*float(pc_ab)/100.\n",
    "    train_y = norm.rvs(loc=train_y,scale=train_y_err)\n",
    "    train_y = torch.tensor(train_y).float()\n",
    "\n",
    "    val_y_err = torch.ones_like(val_y)*float(pc_ab)/100.\n",
    "    val_y = norm.rvs(loc=val_y,scale=val_y_err)\n",
    "    val_y = torch.tensor(val_y).float()\n",
    "\n",
    "    # --- Concatenate the data ---\n",
    "    train_data = torch.cat((train_x, train_y), 1)\n",
    "    val_data = torch.cat((val_x, val_y), 1)\n",
    "\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_442, val_data_442 = load_data('442')\n",
    "train_data_742, val_data_742 = load_data('742')\n",
    "train_data_842, val_data_842 = load_data('842')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize ModelTransfuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTf = ModelTransfuser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Data to ModelTransfuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data added to model Chempy_442\n",
      "Data added to model Chempy_742\n",
      "Data added to model Chempy_842\n"
     ]
    }
   ],
   "source": [
    "MTf.add_data(model_name='Chempy_442', train_data=train_data_442, val_data=val_data_442)\n",
    "MTf.add_data(model_name='Chempy_742', train_data=train_data_742, val_data=val_data_742)\n",
    "MTf.add_data(model_name='Chempy_842', train_data=train_data_842, val_data=val_data_842)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the SBI Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized: ['Chempy_442', 'Chempy_742', 'Chempy_842']\n"
     ]
    }
   ],
   "source": [
    "MTf.init_models(sde_type=\"vesde\", sigma=2.5, hidden_size=36, depth=5, num_heads=1, mlp_ratio=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the SBI Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Chempy_442 trained\n",
      "Model Chempy_742 trained\n",
      "Model Chempy_842 trained\n"
     ]
    }
   ],
   "source": [
    "MTf.train_models(path=\"data/models/test_MTf\", batch_size=862, device=\"cuda\", max_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the Models on Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mask = torch.zeros_like(val_data_842[0])\n",
    "posterior_mask[6:] = 1\n",
    "\n",
    "observations = val_data_842[:10, posterior_mask.type(torch.bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of dimensions is greater than number of samples. This results in a singular data covariance matrix, which cannot be treated using the algorithms implemented in `gaussian_kde`. Note that `gaussian_kde` interprets each *column* of `dataset` to be a point; consider transposing the input to `dataset`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mMTf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposterior_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_corrector_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sbi_model_comparison/src/ModelTransfuser.py:245\u001b[0m, in \u001b[0;36mModelTransfuser.compare\u001b[0;34m(self, observations, condition_mask, timesteps, eps, num_samples, cfg_alpha, multi_obs_inference, hierarchy, order, snr, corrector_steps_interval, corrector_steps, final_corrector_steps, device, verbose, method)\u001b[0m\n\u001b[1;32m    242\u001b[0m null_samples \u001b[38;5;241m=\u001b[39m null_samples[\u001b[38;5;241m0\u001b[39m,:,condition_mask\u001b[38;5;241m.\u001b[39mbool()]\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# Log probability of null hypothesis\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m null_log_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_prob(null_samples, observations[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(observations))])\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats[model_name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_probs_nullHyp\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m null_log_probs\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m####################\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Likelihood sampling\u001b[39;00m\n",
      "File \u001b[0;32m~/sbi_model_comparison/src/ModelTransfuser.py:245\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    242\u001b[0m null_samples \u001b[38;5;241m=\u001b[39m null_samples[\u001b[38;5;241m0\u001b[39m,:,condition_mask\u001b[38;5;241m.\u001b[39mbool()]\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# Log probability of null hypothesis\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m null_log_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnull_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(observations))])\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats[model_name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_probs_nullHyp\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m null_log_probs\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m####################\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Likelihood sampling\u001b[39;00m\n",
      "File \u001b[0;32m~/sbi_model_comparison/src/ModelTransfuser.py:295\u001b[0m, in \u001b[0;36mModelTransfuser._log_prob\u001b[0;34m(self, samples, observation)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, samples, observation):\n\u001b[1;32m    294\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the log probability of the samples\"\"\"\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m     kde \u001b[38;5;241m=\u001b[39m \u001b[43mgaussian_kde\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     log_prob \u001b[38;5;241m=\u001b[39m kde\u001b[38;5;241m.\u001b[39mlogpdf(observation)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_prob\n",
      "File \u001b[0;32m~/anaconda3/envs/simformer_torch/lib/python3.10/site-packages/scipy/stats/_kde.py:223\u001b[0m, in \u001b[0;36mgaussian_kde.__init__\u001b[0;34m(self, dataset, bw_method, weights)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn:\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of dimensions is greater than number of samples. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis results in a singular data covariance matrix, which \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot be treated using the algorithms implemented in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gaussian_kde`. Note that `gaussian_kde` interprets each \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*column* of `dataset` to be a point; consider transposing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe input to `dataset`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bandwidth(bw_method\u001b[38;5;241m=\u001b[39mbw_method)\n",
      "\u001b[0;31mValueError\u001b[0m: Number of dimensions is greater than number of samples. This results in a singular data covariance matrix, which cannot be treated using the algorithms implemented in `gaussian_kde`. Note that `gaussian_kde` interprets each *column* of `dataset` to be a point; consider transposing the input to `dataset`."
     ]
    }
   ],
   "source": [
    "MTf.compare(observations=observations, condition_mask=posterior_mask, timesteps=20, final_corrector_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chempy_442': {}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MTf.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simformer_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
